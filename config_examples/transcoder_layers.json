{
  "model_type": "transcoder",
  "model_name": "HuggingFaceTB/SmolLM2-135M",
  "dataset_name": "EleutherAI/SmolLM2-135M-10B",
  "dataset_split": "train",
  "max_samples": 5000,
  "max_seq_length": 256,
  "expansion_factor": 16,
  "num_latents": 0,
  "k": 16,
  "activation": "topk",
  "normalize_decoder": true,
  "multi_topk": false,
  "skip_connection": false,
  "batch_size": 2,
  "grad_acc_steps": 16,
  "micro_acc_steps": 1,
  "loss_fn": "fvu",
  "optimizer": "adam",
  "lr": 0.0001,
  "lr_warmup_steps": 1000,
  "weight_decay": 0.0,
  "auxk_alpha": 0.03125,
  "dead_feature_threshold": 5000000,
  "k_decay_steps": 20000,
  "layers": [
    6,
    7,
    8
  ],
  "layer_stride": 1,
  "hookpoints": null,
  "max_steps": null,
  "init_seeds": [
    42
  ],
  "finetune": false,
  "exclude_tokens": [],
  "distribute_modules": false,
  "save_dir": "./transcoder_checkpoints",
  "run_name": "transcoder_layers_6_7_8",
  "save_every": 1000,
  "save_best": true,
  "log_to_wandb": true,
  "wandb_project": "transcoder-training",
  "wandb_entity": null,
  "wandb_log_frequency": 100,
  "device": "cuda:1",
  "dtype": "bfloat16"
}